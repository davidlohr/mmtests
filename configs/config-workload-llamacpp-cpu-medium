# LLama.cpp Configuration - CPU Medium Model

# MM Test Parameters
export MMTESTS="llamacpp"

# Test disk to setup (optional)
#export TESTDISK_PARTITION=/dev/sda6
#export TESTDISK_FILESYSTEM=xfs
#export TESTDISK_MKFS_PARAM="-f -d agcount=8"
#export TESTDISK_MOUNT_ARGS=inode64,delaylog,logbsize=262144,nobarrier

# List of monitors
export RUN_MONITOR=yes
export MONITORS_ALWAYS=
export MONITORS_GZIP="proc-vmstat mpstat"
export MONITORS_WITH_LATENCY="vmstat"
export MONITOR_UPDATE_FREQUENCY=10

# LLama.cpp benchmark - Medium model for balanced testing
export LLAMACPP_MODEL_SIZE=$MEMTOTAL_BYTES*4/5            # Memory allocation for model (80% of total RAM)
export LLAMACPP_COMPUTE_BACKEND=cpu                      # Use CPU backend for inference
export LLAMACPP_MIN_THREADS=1                            # Start thread scaling from 1 thread
export LLAMACPP_MAX_THREADS=$NUMCPUS                     # Scale up to all available CPU cores
export LLAMACPP_BATCH_SIZE=512                           # Batch size for processing
export LLAMACPP_ITERATIONS=3                             # Number of benchmark iterations to run
export LLAMACPP_PROMPT_TOKENS=512                        # Number of prompt tokens to process
export LLAMACPP_GEN_TOKENS=128                           # Number of tokens to generate

# Advanced options (optional)
#export LLAMACPP_MODEL_NUMA=distribute                   # NUMA memory distribution strategy
#export LLAMACPP_WARMUP=no                               # Disable warmup for faster testing
#export LLAMACPP_NO_KVOFFLOAD=1                          # Disable KV cache offloading

# Custom model (optional - overrides model size selection)
#export LLAMACPP_MODEL_URL="https://huggingface.co/TheBloke/model-name.gguf"